[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NAULearningDataScience",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "Notebooks/Kendalls_tau.html",
    "href": "Notebooks/Kendalls_tau.html",
    "title": "Kendall rank correlation coefficient (Kendall’s tau)",
    "section": "",
    "text": "The “probability” view\nIn statistics, the Kendall rank correlation coefficient, commonly referred to as Kendall’s tau (τ), is a statistic used to measure the ordinal association between two measured quantities. A T test is a non-parametric hypothesis test for statistical dependence based on the \\(T\\) coefficient. It is a measure of rank correlation: the similarity of the orderings of data when ranked by each of the quantities. It is named after Maurice Kendall, who developed it in 1938, though Gustav Fechner has proposed a similar measure in the context of time series in 1897.\nKendall’s motification was to create a rubust, intuitive measure of association between two rankings–one that was: - non parameteric – meaning it made no assumptions about the distribution of the data - intuative in interpretation – meaning it could be easily understood (based on concordant and discordant pairs) and - suitable for ordinal or ranked data (like preferences, ratings, or scores).\nBefore Kendall’s tau, other correlation measures like Pearson’s correlation coefficient were commonly used, but they assumed linear relationships and required interval or ratio data. Kendall’s tau provided a way to assess relationships in a more flexible manner, especially for non-linear or non-parametric data.\nIn many real-world problems, especially in decision analysis (also social sciences) data are often ordinal – things we can rank but not measure on a precise numerical scale.\nFor example: a hydrologist looking to build a groundwater recharge project, might want to rank potential sites based on suitability critiera, and rank them in suitability from 1 (low suitability) to 5 or 10 (high suitability). Kendall’s tau would allow the hydrologist to assess the association between different ranking criteria (like soil type, proximity to water sources, land use, etc.) without making assumptions about the underlying data distribution.\n## How it works\nImagine two people rank the same set of sites independently based on their expert opinion of suitability for groundwater recharge.\nKendall’s tau looks at all possible pairs of sites (S1 vs S2, S1 vs S3, … S4 vs S5) and asks: - Do the two analysts agree on which site should be ranked higher?\nFor any pair of sites \\((i, j)\\): - The pair is concordant if both analysts put the same site higher.\n(Example: if \\(A\\) says \\(S2\\) better than \\(S5\\), and \\(B\\) also says \\(S2\\) better than \\(S5\\).) - The pair is discordant if the analysts disagree about which one is better.\n(Example: A says \\(S1\\) better than \\(S4\\), but \\(B\\) says \\(S4\\) better than \\(S1\\).) - (Ties are possible in general, though not shown in this simple example. We handle those with slight variations of tau.)\nIntuition: - If most pairs are concordant → \\(\\tau\\) is close to +1 (the rankings mostly agree). - If most pairs are discordant → \\(\\tau\\) is close to −1 (the rankings mostly disagree / almost inverted). - If agreement and disagreement are about equal → \\(\\tau\\) is near 0.\nOne clean way to define Kendall’s tau is:\n\\[\n\\tau = P(\\text{concordant}) - P(\\text{discordant})\n\\]\nHere \\(P(\\text{concordant})\\) means:\n“Out of all possible pairs of items, what fraction of pairs are concordant?”\nIn other words, these are not probabilities in the sense of randomness over repeated experiments — they are proportions over all \\(\\frac{n(n-1)}{2}\\) pairs in this dataset.\nSo you can read \\(\\tau\\) as: &gt; “If I pick two items at random, how much more likely is it that the two rankings agree on their order than disagree?”\nThat’s the core interpretation.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kendall rank correlation coefficient (Kendall's tau)</span>"
    ]
  },
  {
    "objectID": "Notebooks/Kendalls_tau.html#the-counting-pairwise-formula",
    "href": "Notebooks/Kendalls_tau.html#the-counting-pairwise-formula",
    "title": "Kendall rank correlation coefficient (Kendall’s tau)",
    "section": "The counting (pairwise) formula",
    "text": "The counting (pairwise) formula\nLet: - \\(n\\) = number of items being ranked\n- \\(C\\) = number of concordant pairs\n- \\(D\\) = number of discordant pairs\n- \\(T = \\frac{n(n-1)}{2}\\) = total number of distinct pairs\nThen Kendall’s tau can be written as:\n\\[\n\\tau = \\frac{C - D}{T}\n= \\frac{C - D}{\\frac{1}{2} n (n - 1)}\n\\]\nThis is the same as the “probability” version, just written in terms of counts instead of proportions: - \\(\\frac{C}{T}\\) is \\(P(\\text{concordant})\\) - \\(\\frac{D}{T}\\) is \\(P(\\text{discordant})\\)\nSo: \\[\n\\tau = \\frac{C}{T} - \\frac{D}{T}\n\\]\n\nIn practice, we’ll compute \\(C\\) and \\(D\\) from two ranked lists, calculate \\(\\tau\\), and then visualize where disagreements are happening spatially or across alternatives.\nNext, we’ll implement this calculation in Python, both “by hand” (to see C and D) and using scipy.stats.kendalltau.\n\nNow lets explore how to calculate Kendall’s tau using Python.\n\n\n# import pandas to create an manipulate dataframes\nimport pandas as pd\n\n# create a sample dataframe with rankings from two analysts\ndata = pd.DataFrame({\n    \"Site\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"],\n    \"Rank_Analyst1\": [1, 2, 3, 4, 5, 6],  # Analyst 1 thinks A&gt;B&gt;C&gt;D&gt;E&gt;F\n    \"Rank_Analyst2\": [1, 3, 2, 4, 6, 5]   # Analyst 2 mostly agrees, but swaps B/C and E/F\n})\n\ndata\n\n\n\n\n\n\n\n\nSite\nRank_Analyst1\nRank_Analyst2\n\n\n\n\n0\nA\n1\n1\n\n\n1\nB\n2\n3\n\n\n2\nC\n3\n2\n\n\n3\nD\n4\n4\n\n\n4\nE\n5\n6\n\n\n5\nF\n6\n5\n\n\n\n\n\n\n\n\nOk, now lets create a function that checks all possible pairings rankings to determine concordant (agreeing) and discordant (disagreeing) pairs.\n\n\n# itertools is a useful library for creating combinations and permutations\nimport itertools\n\ndef kendall_concordance_table(df, col_x, col_y):\n    \"\"\"\n    Create a table showing concordant and discordant pairs between two rankings.\n    df: DataFrame with rankings\n    col_x: column name for first ranking\n    col_y: column name for second ranking\n    Returns a DataFrame with pairwise comparisons and counts of concordant/discordant pairs.\n    \"\"\"\n    pairs_info = [] # to store info about each pair\n    C = 0  # concordant = they agree on order\n    D = 0  # discordant = they disagree on order\n    for (i, j) in itertools.combinations(df.index, 2): # for all unique pairs of indices (i, j)\n        x_i = df.loc[i, col_x] # x_i is the rank of item i in ranking x\n        x_j = df.loc[j, col_x] # x_j is the rank of item j in ranking x\n        y_i = df.loc[i, col_y] # y_i is the rank of item i in ranking y\n        y_j = df.loc[j, col_y] # y_j is the rank of item j in ranking y\n        site_i = df.loc[i, \"Site\"] # get site names for reporting for item i\n        site_j = df.loc[j, \"Site\"] # get site names for reporting for item j\n\n        # Compare pair ordering in each ranking\n        diff_x = x_i - x_j # difference in ranking for pair (i, j) in ranking x\n        diff_y = y_i - y_j # difference in ranking for pair (i, j) in ranking y\n\n        # If both differences have same sign -&gt; concordant\n        # If opposite sign -&gt; discordant\n        # If diff_x or diff_y == 0, that's a tie (we'll just mark it)\n        if diff_x * diff_y &gt; 0:\n            relation = \"concordant\"\n            C += 1\n        elif diff_x * diff_y &lt; 0:\n            relation = \"discordant\"\n            D += 1\n        else:\n            relation = \"tie\"\n\n        pairs_info.append({\n            \"Pair\": f\"{site_i}-{site_j}\",\n            f\"Order in {col_x}\": \"i&lt;j\" if diff_x &lt; 0 else \"i&gt;j\",\n            f\"Order in {col_y}\": \"i&lt;j\" if diff_y &lt; 0 else \"i&gt;j\",\n            \"Relation\": relation\n        })\n\n    pairs_df = pd.DataFrame(pairs_info)\n    return pairs_df, C, D\n\n# Now let's use the function on our sample data\npairs_df, C, D = kendall_concordance_table(data, \"Rank_Analyst1\", \"Rank_Analyst2\")\nprint(f\"Concordant pairs (C): {C}, Discordant pairs (D): {D}\") # print out the counts of concordant and discordant pairs\npairs_df # print the output table from the function: kendall_concordance_table()\n\nConcordant pairs (C): 13, Discordant pairs (D): 2\n\n\n\n\n\n\n\n\n\nPair\nOrder in Rank_Analyst1\nOrder in Rank_Analyst2\nRelation\n\n\n\n\n0\nA-B\ni&lt;j\ni&lt;j\nconcordant\n\n\n1\nA-C\ni&lt;j\ni&lt;j\nconcordant\n\n\n2\nA-D\ni&lt;j\ni&lt;j\nconcordant\n\n\n3\nA-E\ni&lt;j\ni&lt;j\nconcordant\n\n\n4\nA-F\ni&lt;j\ni&lt;j\nconcordant\n\n\n5\nB-C\ni&lt;j\ni&gt;j\ndiscordant\n\n\n6\nB-D\ni&lt;j\ni&lt;j\nconcordant\n\n\n7\nB-E\ni&lt;j\ni&lt;j\nconcordant\n\n\n8\nB-F\ni&lt;j\ni&lt;j\nconcordant\n\n\n9\nC-D\ni&lt;j\ni&lt;j\nconcordant\n\n\n10\nC-E\ni&lt;j\ni&lt;j\nconcordant\n\n\n11\nC-F\ni&lt;j\ni&lt;j\nconcordant\n\n\n12\nD-E\ni&lt;j\ni&lt;j\nconcordant\n\n\n13\nD-F\ni&lt;j\ni&lt;j\nconcordant\n\n\n14\nE-F\ni&lt;j\ni&gt;j\ndiscordant",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kendall rank correlation coefficient (Kendall's tau)</span>"
    ]
  },
  {
    "objectID": "Notebooks/Kendalls_tau.html#compute-kendalls-tau-from-first-principles",
    "href": "Notebooks/Kendalls_tau.html#compute-kendalls-tau-from-first-principles",
    "title": "Kendall rank correlation coefficient (Kendall’s tau)",
    "section": "Compute Kendall’s Tau from first principles",
    "text": "Compute Kendall’s Tau from first principles\nNext we will compute Kendall’s tau manually using Python.\nremember that tau is the difference between the probability of concordant and discordant pairs.\nFor \\(n\\) items, the total number of distince pairs is given by the formula: \\(T = \\frac{n(n-1)}{2}\\).\nThen, we can use the output of the function above which counted the number of concordant and discordant pairs to compute kendall’s tau.\n\nimport numpy as np # for numerical operations we use numpy\n\nn = len(data) # number of items being ranked\ntotal_pairs = n * (n - 1) / 2 # total number of distinct pairs T\ntau_manual = (C - D) / total_pairs # Kendall's tau formula\n\nprint(f\" C = {C}, D = {D}, Total pairs (T): {total_pairs}\")\nprint(f\"Kendall's tau (manual calculation): {tau_manual:.3f}\")\n\n C = 13, D = 2, Total pairs (T): 15.0\nKendall's tau (manual calculation): 0.733\n\n\n\nInterpreting the results\n\nif tau is close to +1, the rankings mostly agree if tau is close to 0.5, mostly agree but with notable flips if tau is close to -1, the rankings mostly disagree if tau is close to -0.5, mostly disagree but with agreements if tau is close to 0, there is little association between the rankings\nFor this synthetic dataset we should see \\(\\tau\\) as high but not 1 because those B vs C and E vs F swaps create discordance.\n\nNext lets visualize the agreement and disagreement between the two rankings.\n\nTo do this we will plot…\n\nimport matplotlib.pyplot as plt\n\ncolor_map = { 'concordant': 'green', 'discordant': 'red', \"tie\": 'gray' }\n\nplt.figure(figsize=(10, 6))\npair_counts = pairs_df[\"Relation\"].value_counts()\nbars = plt.bar(pair_counts.index, pair_counts.values,\n               color=[color_map[r] for r in pair_counts.index])\n\nplt.ylabel(\"Number of Pairs\")\nplt.title(\"Counts of Concordant and Discordant Pairs\")\nplt.show()\n\n\n\n\n\n\n\n\nSo looking at the figure we can see that most of the pairs are concordant, we have a few discordant pairs (in red) and no ties (gray). We got a kendall’s tau of 0.733 which indicates a strong positive association between the two rankings.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kendall rank correlation coefficient (Kendall's tau)</span>"
    ]
  },
  {
    "objectID": "Notebooks/Kendalls_tau.html#compare-manual-calculation-to-scipy.stats",
    "href": "Notebooks/Kendalls_tau.html#compare-manual-calculation-to-scipy.stats",
    "title": "Kendall rank correlation coefficient (Kendall’s tau)",
    "section": "Compare manual calculation to scipy.stats",
    "text": "Compare manual calculation to scipy.stats\nNow that we understand the basic calculation of Kendall’s tau, lets try to use the scipy.stats version of kendall’s tau to see if we get the same results and how our manual calculation compares to the built-in function in scipy.stats\n\nfrom scipy.stats import kendalltau # import kendalltau from scipy.stats\n\n# recall the structure of our data\nprint(data.columns) # show column names\ndata.head(5) # show first 5 rows of data\n\nIndex(['Site', 'Rank_Analyst1', 'Rank_Analyst2'], dtype='object')\n\n\n\n\n\n\n\n\n\nSite\nRank_Analyst1\nRank_Analyst2\n\n\n\n\n0\nA\n1\n1\n\n\n1\nB\n2\n3\n\n\n2\nC\n3\n2\n\n\n3\nD\n4\n4\n\n\n4\nE\n5\n6\n\n\n\n\n\n\n\n\ntau_scipy, p_value = kendalltau(data[\"Rank_Analyst1\"], data[\"Rank_Analyst2\"])\nprint(f\"Kendall's tau (scipy.stats): {tau_scipy:.3f}, p-value: {p_value:.3f}\")\n\nKendall's tau (scipy.stats): 0.733, p-value: 0.056\n\n\nNotice that both our manual calculation and scipy’s kendalltau function give the same result of approximately 0.733, confirming the correctness of our manual implementation. But the scipy function also provides a p-value for testing the hypothesis of no association (\\(\\tau = 0\\))\nSo the scipy version does two things:\n\nIt computes Kendall’s tau using an efficient algorithm measuring the strength of monotonic association between two rankings.\nIt provides a p-value for testing the null hypothesis that there is no association between the two rankings (i.e., \\(\\tau = 0\\)). A low p-value (typically &lt; 0.05) indicates that we can reject the null hypothesis and conclude that there is a statistically significant association between the rankings.\n\nHere we got a p-value of approximately 0.056, which indicates that the association is marginally significant at the 0.05 level. This suggests that while there is a positive association between the rankings, we should be cautious in interpreting it as statistically significant. Why? Because our sample dataset is small (only 5 items), with a such a small number of pairs its more likely that random chance could produce similar levels of concordance. lets see what happens when we increase the size of the dataset.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kendall rank correlation coefficient (Kendall's tau)</span>"
    ]
  },
  {
    "objectID": "Notebooks/Kendalls_tau.html#adding-complexity",
    "href": "Notebooks/Kendalls_tau.html#adding-complexity",
    "title": "Kendall rank correlation coefficient (Kendall’s tau)",
    "section": "Adding complexity",
    "text": "Adding complexity\nTo further explore the behavior of Kendall’s tau, we can increase the size of our dataset from 6 sites to 30. We will randomly generate base ranking, then create a slightly “noisy” version to simulate small differences in judgement or weight perturbations.\n\nnp.random.seed(32)  # for reproducibility\nn = 100 # change this and re-run as well to see the effect of sample size \nswap_n = 30 # number of swaps to introduce, change this value and re-run to see different levels of disagreement\n\n# Analyst A: perfect ranking 1 -&gt; n\nrank_A = np.arange(1, n + 1) # Analyst A ranks items from 1 to n\n\n# Analyst B: same order bit with some random swaps (simulateing disagreement)\nrank_B = rank_A.copy() # start with same ranking as Analyst A\nswap_indices = np.random.choice(n, size=swap_n, replace=False) # choose 5 random indices to swap\nnp.random.shuffle(swap_indices) # shuffle the selected indices\nrank_B[swap_indices] = rank_B[np.random.permutation(swap_indices)]  # perform the swaps\n\ntau, p_value = kendalltau(rank_A, rank_B)\nprint(f\"Kendall's tau between Analyst A and B: {tau:.3f}, p-value: {p_value:.3f}\")\n\n# Visualize the rankings in a scatter plot\nplt.figure(figsize=(5,5))\nplt.scatter(rank_A, rank_B)\nplt.plot([0,n],[0,n],'k--',alpha=0.5)\nplt.xlabel(\"Analyst A rank\")\nplt.ylabel(\"Analyst B rank\")\nplt.title(f\"n = {n}, τ = {tau:.3f}\")\nplt.show()\n\n\nKendall's tau between Analyst A and B: 0.593, p-value: 0.000\n\n\n\n\n\n\n\n\n\n\nNext lets add noise a different way.\n\nFirst we will create a set of data, we will call base_scores we will just take \\(n\\) numbers spaced equally from 0 to 1\nthen we will create alternative scores which are the base_scores with some noise added, noise from a random normal distribution.\n\n\nn = 19 # change this depending on the sample size you want\nnoise_factor = 0.08 # this is the standard devation of the distribution from which the noise is generated, try 0.1, 0.05, 1, see how this affects kendalls tau\nbase_scores = np.linspace(0,1,n)\n#print(f\"base_scores {base_scores}\")\n\nnoise = np.random.normal (0,noise_factor,n) # create noise by drawing random samples from a normal gaussian distribution\n\nalt_scores = base_scores + noise # add the noise to the base scores to create alternative scores\n#print(f\"alt scores (base scores + noise) {alt_scores}\")\n\nrank_base = pd.Series(base_scores).rank() # rank the original scores, (remember we want ranks not scores)\nrank_alt = pd.Series(alt_scores).rank() # the base scores have been changed a bit randomly so they will rank differently when their rank is calculated\n\n# now lets calculate kendall's tau\n\ntau, p_value = kendalltau(rank_base, rank_alt)\nprint(f\"τ = {tau:.3f}; pvalue = {p_value:.5f}\")\n\nτ = 0.860; pvalue = 0.00000\n\n\n\n# plot the relationship between rank_base, and rank_alt (our two different rankings)\n\nplt.figure(figsize=(6,4))\nplt.scatter(base_scores, alt_scores)\nplt.xlabel(\"Suitability A\")\nplt.ylabel(\"Suitability B (perturbed)\")\nplt.title(f\"Kendall’s τ = {tau:.3f}\")\nplt.show()\n\n\n\n\n\n\n\n\n\nLets now look at how changing the level of noise in the data affects the kendalls tau\n\nWe will generate many random pertubations and compute \\(\\tau\\) each time. This mimics the way sensitivity analysis samples random weight combinations in a Weighted Linear Combination (WLC). basically we are looking at the kendall’s tau through time, and automating the changing of the standard devation within the noise addition to see how adding different levels of noise affects kendall’s tau.\n\n\nnoise_levels = np.linspace(0,0.5,20)\n#print(noise_levels)\n\ntaus = []\n\nfor s in noise_levels:\n    alt = base_scores + np.random.normal(0 , s , n) # recall n is defined above in previous example as is base_scores\n    taus.append(kendalltau(pd.Series(base_scores).rank(), pd.Series(alt).rank())[0])\n\n\nplt.plot(noise_levels, taus, marker='o')\nplt.xlabel(\"Noise (std dev)\")\nplt.ylabel(\"Kendall’s τ\")\nplt.title(\"Rank stability vs. perturbation level\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nyou can see from the above figure that as noise increases kendall’s tau a measure of similarity between rankings decreases, rank stability decreases.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kendall rank correlation coefficient (Kendall's tau)</span>"
    ]
  },
  {
    "objectID": "Notebooks/Kendalls_tau.html#real-world-example---countries-ranked-by-life-expectency-and-gdp",
    "href": "Notebooks/Kendalls_tau.html#real-world-example---countries-ranked-by-life-expectency-and-gdp",
    "title": "Kendall rank correlation coefficient (Kendall’s tau)",
    "section": "real-world example - Countries Ranked by Life Expectency and GDP",
    "text": "real-world example - Countries Ranked by Life Expectency and GDP\nOk, enough with fake data sets, lets step away from the hard sciences for a second and look at something more social. Lets look at how life expectancy compares to GDP, we would think life expectancy is higher in rich countries and lower in poor countries. So we can get the data on life expectancy, and we can get the data on GDP, then rank the countries in order of GDP and life expectancy, and compare how these two different ways to rank countries are concordant or discordant using Kendalls Tau\n\nto see how we cleaned and created these datasets see this notebook: Data\\DataWranglingScripts\\GDPvLifeExpectency2022_countries_ranked.ipynb\n\n\ndf = pd.read_csv(\"../Data/CLEAN/GDP_LifeExpectancy_2022_Clean.csv\")\nprint(df.head())\nprint(df.columns)\n\n                  Country Name Country Code   GDP_PC_2022  LIFE_EX_YRS_2022  \\\n0                        Aruba          ABW  30559.533535         73.537000   \n1  Africa Eastern and Southern          AFE   1628.318944         61.765707   \n2                  Afghanistan          AFG    357.261153         63.941000   \n3   Africa Western and Central          AFW   1796.668633         56.906135   \n4                       Angola          AGO   2929.694455         61.748000   \n\n   GDP_PC_RANK_2022  LIFE_EX_YRS_RANK_2022  \n0              56.0                   86.0  \n1             216.0                  220.0  \n2             255.0                  203.0  \n3             210.0                  251.0  \n4             187.0                  221.0  \nIndex(['Country Name', 'Country Code', 'GDP_PC_2022', 'LIFE_EX_YRS_2022',\n       'GDP_PC_RANK_2022', 'LIFE_EX_YRS_RANK_2022'],\n      dtype='object')\n\n\n\ntau, pval = kendalltau(df[\"GDP_PC_RANK_2022\"], df[\"LIFE_EX_YRS_RANK_2022\"])\n\nprint(f\"Kendall's tau (τ) = {tau:.3f}\")\nprint(f\"p-value = {pval:.8f}\")\n\nKendall's tau (τ) = 0.651\np-value = 0.00000000\n\n\nWe see a strong positive rank correlation, which is what we would expect. Wealthier countries generally have longer life expectancy, though the relationship isnt perfect. Now lets visualize the data.\n\nplt.figure(figsize=(7,7))\nplt.scatter(\n    df[\"GDP_PC_RANK_2022\"],\n    df[\"LIFE_EX_YRS_RANK_2022\"],\n    alpha=0.7,\n    edgecolor=\"k\",\n    linewidth=0.3\n)\n\n# Add a diagonal \"perfect agreement\" line\nplt.plot(\n    [1, df[\"GDP_PC_RANK_2022\"].max()],\n    [1, df[\"LIFE_EX_YRS_RANK_2022\"].max()],\n    'k--', alpha=0.5, label=\"Perfect rank agreement\"\n)\n\nplt.xlabel(\"GDP per capita rank (1 = richest)\")\nplt.ylabel(\"Life expectancy rank (1 = longest-lived)\")\nplt.title(f\"Country Rank Agreement\\nKendall’s τ = {tau:.3f}\")\n\n# Flip axes so 'better' (rank 1) appears top-right\nplt.gca().invert_xaxis()\nplt.gca().invert_yaxis()\nplt.legend()\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nNext we will zoom in on the top 40 countries in terms of GDP and see if the kendalls tau is better or worse when we exclude all but the 40 richest.\n\n# Sort by GDP rank (1 = richest)\ndf_top40 = (\n    df\n    .sort_values(\"GDP_PC_RANK_2022\", ascending=True)\n    .head(40)\n    .copy()\n)\n\nprint(df_top40[[\"Country Name\", \"GDP_PC_RANK_2022\", \"LIFE_EX_YRS_RANK_2022\"]].head())\nprint(f\"Number of countries in subset: {len(df_top40)}\")\n\n      Country Name  GDP_PC_RANK_2022  LIFE_EX_YRS_RANK_2022\n144         Monaco               1.0                    2.0\n133  Liechtenstein               2.0                    3.0\n140     Luxembourg               3.0                   14.0\n27         Bermuda               4.0                   42.0\n172         Norway               5.0                   11.0\nNumber of countries in subset: 40\n\n\n\ntau_top, pval_top = kendalltau(\n    df_top40[\"GDP_PC_RANK_2022\"],\n    df_top40[\"LIFE_EX_YRS_RANK_2022\"]\n)\n\nprint(f\"Kendall’s τ (top 40 richest) = {tau_top:.3f}\")\nprint(f\"p-value = {pval_top:.8f}\")\n\nKendall’s τ (top 40 richest) = 0.248\np-value = 0.02515424\n\n\n\ndf_top40[\"RankGap\"] = (\n    df_top40[\"GDP_PC_RANK_2022\"] - df_top40[\"LIFE_EX_YRS_RANK_2022\"]\n)\n\nplt.figure(figsize=(8,8))\nscatter = plt.scatter(\n    df_top40[\"GDP_PC_RANK_2022\"],\n    df_top40[\"LIFE_EX_YRS_RANK_2022\"],\n    c=df_top40[\"RankGap\"],\n    cmap=\"RdBu_r\",\n    s=70,\n    edgecolor=\"k\",\n    linewidth=0.4\n)\nplt.colorbar(scatter, label=\"Rank Gap (GDP − Life Exp)\")\n\nplt.plot(\n    [1, df_top40[\"GDP_PC_RANK_2022\"].max()],\n    [1, df_top40[\"LIFE_EX_YRS_RANK_2022\"].max()],\n    'k--', alpha=0.4\n)\n\nfor _, row in df_top40.iterrows():\n    plt.text(\n        row[\"GDP_PC_RANK_2022\"] + 0.2,\n        row[\"LIFE_EX_YRS_RANK_2022\"],\n        row[\"Country Name\"],\n        fontsize=8\n    )\n\nplt.xlabel(\"GDP per capita rank (1 = richest)\")\nplt.ylabel(\"Life expectancy rank (1 = longest-lived)\")\nplt.title(f\"Top 40 Wealthiest Countries: Over / Under-Performers\\nτ = {tau_top:.3f}\")\n\nplt.gca().invert_xaxis()\nplt.gca().invert_yaxis()\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe analysis of country rank in terms of GDP per capita vs life expectancy using Kendall’s tau tells us that overall life expectency is correlated with GDP per capita in terms of how contries compare to eachother (rank), however the correlation is much worse in the rich countries, why might that be?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kendall rank correlation coefficient (Kendall's tau)</span>"
    ]
  },
  {
    "objectID": "Notebooks/Kendalls_tau.html#conceptual-questions",
    "href": "Notebooks/Kendalls_tau.html#conceptual-questions",
    "title": "Kendall rank correlation coefficient (Kendall’s tau)",
    "section": "CONCEPTUAL QUESTIONS",
    "text": "CONCEPTUAL QUESTIONS\n\nIs Kendall’s Tau a good way to measure the correlation of these two variables?\n\n\nanswer: Its more approriate to look at how the Life Expectency values compare to the GDP per capita directly using Pearson’s R, which compares one number to another. Kendall’s Tau is for comparing the ranks, so the colored rank figure shows us that countries below the line, are under performing in terms of life expectancy vs GDP relative to their neighbors. It is also telling us the the GDP life expectency relationship breaks down at higher levels of GDP or is less meaningful.\n\n\nWhy might this relationship breakdown when subsetting the data to only the richest countries?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kendall rank correlation coefficient (Kendall's tau)</span>"
    ]
  },
  {
    "objectID": "Notebooks/Kendalls_tau.html#spatial-rank-correlation",
    "href": "Notebooks/Kendalls_tau.html#spatial-rank-correlation",
    "title": "Kendall rank correlation coefficient (Kendall’s tau)",
    "section": "Spatial Rank Correlation",
    "text": "Spatial Rank Correlation\n\nUsing Kendalls Tau for suitability mapping sensitivity Analysis\n\nIn a Weighted Linear Combination (WLC) or other GIS-MCDA, you often generate suitability rasters under different weighting schemes, e.g.:\n\nScenario A: baseline weights (e.g., 40% slope, 30% soil, 30% rainfall)\nScenario B: modified weights (e.g., 30% slope, 40% soil, 30% rainfall)\n\nEach raster cell gets a suitability score. You can rank cells (1 = most suitable) for each scenario, then compute Kendall’s \\(\\tau\\) between the two rankings.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kendall rank correlation coefficient (Kendall's tau)</span>"
    ]
  },
  {
    "objectID": "Notebooks/Kendalls_tau.html#simulated-mcda-suitability",
    "href": "Notebooks/Kendalls_tau.html#simulated-mcda-suitability",
    "title": "Kendall rank correlation coefficient (Kendall’s tau)",
    "section": "simulated MCDA suitability",
    "text": "simulated MCDA suitability\nWe will build two small 10x10 rasteres (100 cells):\nsuitability_A –&gt; Baseline Scenario suitability_B –&gt; slightly perturbed version (change one weight layer)\n\nThen flatted both to 1D arrays (each cell = one observation)\ncompute \\(\\tau\\) for the full map\nvisualize where ranks changed the most.\n\n\nnp.random.seed(42)\n\n# --- Step 1: create two synthetic suitability grids (values 1–10) ---\ngrid_size = 10\nsuitability_A = np.random.rand(grid_size, grid_size) * 9 + 1  # values in [1,10]\nsuitability_B = suitability_A + np.random.normal(0, 0.02, (grid_size, grid_size))  # add mild noise\nsuitability_B = np.clip(suitability_B, 1, 10)  # keep within same range\n\ndiff = suitability_A - suitability_B\n\n# --- Step 2: plot them side-by-side ---\nfig, axes = plt.subplots(1, 3, figsize=(10, 4))\n\nim1 = axes[0].imshow(suitability_A, cmap=\"YlGn\", vmin=1, vmax=10)\naxes[0].set_title(\"Scenario A — Baseline\")\naxes[0].axis(\"off\")\nplt.colorbar(im1, ax=axes[0], fraction=0.046, pad=0.04, label=\"Suitability (1–10)\")\n\nim2 = axes[1].imshow(suitability_B, cmap=\"YlGn\", vmin=1, vmax=10)\naxes[1].set_title(\"Scenario B — Perturbed\")\naxes[1].axis(\"off\")\nplt.colorbar(im2, ax=axes[1], fraction=0.046, pad=0.04, label=\"Suitability (1–10)\")\n\nim3 = axes[2].imshow(diff, cmap = 'RdBu', vmin = diff.min(), vmax = diff.max())\naxes[2].set_title(\"Difference (added noise)\")\naxes[2].axis('off')\nplt.colorbar(im3, ax=axes[2], fraction=0.046, pad = 0.04, label=\"Difference\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# --- Step 3: compute Kendall’s tau on the flattened ranks ---\nA_flat = suitability_A.flatten()\nB_flat = suitability_B.flatten()\n\nrank_A = pd.Series(A_flat).rank()\nrank_B = pd.Series(B_flat).rank()\n\ntau, pval = kendalltau(rank_A, rank_B)\nprint(f\"Overall spatial Kendall’s τ = {tau:.3f} -- Pvalue: {pval:.4f}\")\n\nOverall spatial Kendall’s τ = 0.997 -- Pvalue: 0.0000\n\n\n\nrank_diff = (rank_B - rank_A).values.reshape(grid_size, grid_size)\n\nplt.figure(figsize=(6,5))\nplt.imshow(rank_diff, cmap=\"BrBG\", vmin=rank_diff.min(), vmax=rank_diff.max())\nplt.colorbar(label=\"Rank difference (B − A)\")\nplt.title(\"Spatial distribution of rank changes\")\nplt.axis(\"off\")\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kendall rank correlation coefficient (Kendall's tau)</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  }
]